{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:116: RuntimeWarning: The _imaging extension was built for another version of Pillow or PIL:\n",
      "Core version: 4.2.1\n",
      "Pillow version: 6.1.0\n",
      "  warnings.warn(str(v), RuntimeWarning)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:116: RuntimeWarning: The _imaging extension was built for another version of Pillow or PIL:\n",
      "Core version: 4.2.1\n",
      "Pillow version: 6.1.0\n",
      "  warnings.warn(str(v), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n",
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n",
      "Build model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 23s 503us/step - loss: 1.8814 - accuracy: 0.3232 - val_loss: 1.7773 - val_accuracy: 0.3493\n",
      "Q 574+18  T 592  \u001b[91m☒\u001b[0m 151 \n",
      "Q 184+2   T 186  \u001b[91m☒\u001b[0m 44  \n",
      "Q 500+0   T 500  \u001b[91m☒\u001b[0m 55  \n",
      "Q 762+99  T 861  \u001b[91m☒\u001b[0m 106 \n",
      "Q 12+775  T 787  \u001b[91m☒\u001b[0m 151 \n",
      "Q 62+9    T 71   \u001b[91m☒\u001b[0m 65  \n",
      "Q 859+67  T 926  \u001b[91m☒\u001b[0m 105 \n",
      "Q 196+656 T 852  \u001b[91m☒\u001b[0m 105 \n",
      "Q 386+3   T 389  \u001b[91m☒\u001b[0m 44  \n",
      "Q 0+949   T 949  \u001b[91m☒\u001b[0m 151 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 412us/step - loss: 1.7135 - accuracy: 0.3687 - val_loss: 1.6254 - val_accuracy: 0.3959\n",
      "Q 531+957 T 1488 \u001b[91m☒\u001b[0m 1443\n",
      "Q 677+0   T 677  \u001b[91m☒\u001b[0m 776 \n",
      "Q 8+822   T 830  \u001b[91m☒\u001b[0m 184 \n",
      "Q 67+377  T 444  \u001b[91m☒\u001b[0m 774 \n",
      "Q 998+76  T 1074 \u001b[91m☒\u001b[0m 904 \n",
      "Q 39+754  T 793  \u001b[91m☒\u001b[0m 494 \n",
      "Q 398+31  T 429  \u001b[91m☒\u001b[0m 494 \n",
      "Q 70+211  T 281  \u001b[91m☒\u001b[0m 222 \n",
      "Q 743+744 T 1487 \u001b[91m☒\u001b[0m 1443\n",
      "Q 943+8   T 951  \u001b[91m☒\u001b[0m 144 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 20s 455us/step - loss: 1.5602 - accuracy: 0.4149 - val_loss: 1.5040 - val_accuracy: 0.4360\n",
      "Q 967+748 T 1715 \u001b[91m☒\u001b[0m 1505\n",
      "Q 201+244 T 445  \u001b[91m☒\u001b[0m 591 \n",
      "Q 156+96  T 252  \u001b[91m☒\u001b[0m 691 \n",
      "Q 23+15   T 38   \u001b[91m☒\u001b[0m 20  \n",
      "Q 146+50  T 196  \u001b[91m☒\u001b[0m 261 \n",
      "Q 859+81  T 940  \u001b[91m☒\u001b[0m 901 \n",
      "Q 93+490  T 583  \u001b[91m☒\u001b[0m 490 \n",
      "Q 0+860   T 860  \u001b[91m☒\u001b[0m 896 \n",
      "Q 131+809 T 940  \u001b[91m☒\u001b[0m 901 \n",
      "Q 391+69  T 460  \u001b[91m☒\u001b[0m 290 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 546us/step - loss: 1.4193 - accuracy: 0.4659 - val_loss: 1.3610 - val_accuracy: 0.4886\n",
      "Q 12+579  T 591  \u001b[91m☒\u001b[0m 583 \n",
      "Q 75+99   T 174  \u001b[91m☒\u001b[0m 163 \n",
      "Q 898+0   T 898  \u001b[91m☒\u001b[0m 986 \n",
      "Q 21+306  T 327  \u001b[91m☒\u001b[0m 236 \n",
      "Q 135+516 T 651  \u001b[91m☒\u001b[0m 608 \n",
      "Q 90+908  T 998  \u001b[91m☒\u001b[0m 901 \n",
      "Q 62+688  T 750  \u001b[91m☒\u001b[0m 728 \n",
      "Q 58+59   T 117  \u001b[91m☒\u001b[0m 12  \n",
      "Q 19+10   T 29   \u001b[91m☒\u001b[0m 10  \n",
      "Q 62+915  T 977  \u001b[91m☒\u001b[0m 986 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 24s 531us/step - loss: 1.3018 - accuracy: 0.5125 - val_loss: 1.2499 - val_accuracy: 0.5369\n",
      "Q 21+880  T 901  \u001b[91m☒\u001b[0m 855 \n",
      "Q 240+3   T 243  \u001b[91m☒\u001b[0m 236 \n",
      "Q 494+33  T 527  \u001b[91m☒\u001b[0m 400 \n",
      "Q 694+8   T 702  \u001b[91m☒\u001b[0m 695 \n",
      "Q 903+485 T 1388 \u001b[91m☒\u001b[0m 1433\n",
      "Q 250+157 T 407  \u001b[91m☒\u001b[0m 355 \n",
      "Q 47+247  T 294  \u001b[91m☒\u001b[0m 330 \n",
      "Q 281+867 T 1148 \u001b[91m☒\u001b[0m 1133\n",
      "Q 22+933  T 955  \u001b[91m☒\u001b[0m 911 \n",
      "Q 78+154  T 232  \u001b[91m☒\u001b[0m 233 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 21s 471us/step - loss: 1.2020 - accuracy: 0.5522 - val_loss: 1.1593 - val_accuracy: 0.5685\n",
      "Q 26+246  T 272  \u001b[92m☑\u001b[0m 272 \n",
      "Q 657+80  T 737  \u001b[91m☒\u001b[0m 722 \n",
      "Q 0+860   T 860  \u001b[91m☒\u001b[0m 822 \n",
      "Q 76+778  T 854  \u001b[91m☒\u001b[0m 841 \n",
      "Q 512+42  T 554  \u001b[91m☒\u001b[0m 558 \n",
      "Q 535+99  T 634  \u001b[91m☒\u001b[0m 622 \n",
      "Q 53+963  T 1016 \u001b[91m☒\u001b[0m 1011\n",
      "Q 81+459  T 540  \u001b[91m☒\u001b[0m 528 \n",
      "Q 20+788  T 808  \u001b[91m☒\u001b[0m 771 \n",
      "Q 560+577 T 1137 \u001b[91m☒\u001b[0m 1181\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 22s 485us/step - loss: 1.1132 - accuracy: 0.5877 - val_loss: 1.0672 - val_accuracy: 0.6136\n",
      "Q 7+945   T 952  \u001b[91m☒\u001b[0m 954 \n",
      "Q 784+10  T 794  \u001b[91m☒\u001b[0m 790 \n",
      "Q 800+880 T 1680 \u001b[91m☒\u001b[0m 1720\n",
      "Q 877+6   T 883  \u001b[91m☒\u001b[0m 880 \n",
      "Q 92+380  T 472  \u001b[91m☒\u001b[0m 444 \n",
      "Q 52+92   T 144  \u001b[92m☑\u001b[0m 144 \n",
      "Q 61+671  T 732  \u001b[91m☒\u001b[0m 724 \n",
      "Q 411+95  T 506  \u001b[91m☒\u001b[0m 504 \n",
      "Q 46+523  T 569  \u001b[91m☒\u001b[0m 566 \n",
      "Q 742+685 T 1427 \u001b[91m☒\u001b[0m 1414\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 24s 530us/step - loss: 1.0401 - accuracy: 0.6164 - val_loss: 1.0023 - val_accuracy: 0.6369\n",
      "Q 335+928 T 1263 \u001b[91m☒\u001b[0m 1298\n",
      "Q 210+285 T 495  \u001b[91m☒\u001b[0m 505 \n",
      "Q 9+548   T 557  \u001b[91m☒\u001b[0m 563 \n",
      "Q 394+393 T 787  \u001b[91m☒\u001b[0m 750 \n",
      "Q 823+75  T 898  \u001b[91m☒\u001b[0m 807 \n",
      "Q 78+704  T 782  \u001b[91m☒\u001b[0m 777 \n",
      "Q 121+79  T 200  \u001b[91m☒\u001b[0m 202 \n",
      "Q 79+30   T 109  \u001b[91m☒\u001b[0m 112 \n",
      "Q 9+389   T 398  \u001b[91m☒\u001b[0m 394 \n",
      "Q 51+967  T 1018 \u001b[91m☒\u001b[0m 1017\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 22s 481us/step - loss: 0.9790 - accuracy: 0.6420 - val_loss: 0.9722 - val_accuracy: 0.6402\n",
      "Q 135+516 T 651  \u001b[91m☒\u001b[0m 687 \n",
      "Q 871+21  T 892  \u001b[91m☒\u001b[0m 890 \n",
      "Q 892+73  T 965  \u001b[91m☒\u001b[0m 950 \n",
      "Q 29+803  T 832  \u001b[91m☒\u001b[0m 838 \n",
      "Q 770+443 T 1213 \u001b[91m☒\u001b[0m 1211\n",
      "Q 901+69  T 970  \u001b[91m☒\u001b[0m 973 \n",
      "Q 343+371 T 714  \u001b[92m☑\u001b[0m 714 \n",
      "Q 895+37  T 932  \u001b[91m☒\u001b[0m 934 \n",
      "Q 9+71    T 80   \u001b[91m☒\u001b[0m 87  \n",
      "Q 93+319  T 412  \u001b[91m☒\u001b[0m 403 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 549us/step - loss: 0.9307 - accuracy: 0.6618 - val_loss: 0.9093 - val_accuracy: 0.6715\n",
      "Q 67+37   T 104  \u001b[91m☒\u001b[0m 100 \n",
      "Q 842+835 T 1677 \u001b[91m☒\u001b[0m 1645\n",
      "Q 974+294 T 1268 \u001b[91m☒\u001b[0m 1250\n",
      "Q 40+171  T 211  \u001b[91m☒\u001b[0m 212 \n",
      "Q 41+746  T 787  \u001b[91m☒\u001b[0m 780 \n",
      "Q 658+40  T 698  \u001b[91m☒\u001b[0m 600 \n",
      "Q 7+760   T 767  \u001b[92m☑\u001b[0m 767 \n",
      "Q 80+681  T 761  \u001b[91m☒\u001b[0m 767 \n",
      "Q 961+476 T 1437 \u001b[91m☒\u001b[0m 1442\n",
      "Q 956+72  T 1028 \u001b[91m☒\u001b[0m 1022\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 25s 559us/step - loss: 0.8901 - accuracy: 0.6762 - val_loss: 0.8796 - val_accuracy: 0.6765\n",
      "Q 182+64  T 246  \u001b[91m☒\u001b[0m 247 \n",
      "Q 5+719   T 724  \u001b[91m☒\u001b[0m 729 \n",
      "Q 94+645  T 739  \u001b[91m☒\u001b[0m 737 \n",
      "Q 856+244 T 1100 \u001b[91m☒\u001b[0m 1009\n",
      "Q 458+63  T 521  \u001b[91m☒\u001b[0m 516 \n",
      "Q 699+969 T 1668 \u001b[91m☒\u001b[0m 1669\n",
      "Q 172+6   T 178  \u001b[91m☒\u001b[0m 179 \n",
      "Q 572+2   T 574  \u001b[91m☒\u001b[0m 579 \n",
      "Q 845+0   T 845  \u001b[91m☒\u001b[0m 847 \n",
      "Q 848+16  T 864  \u001b[91m☒\u001b[0m 861 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 22s 487us/step - loss: 0.8472 - accuracy: 0.6925 - val_loss: 0.8310 - val_accuracy: 0.6973\n",
      "Q 406+2   T 408  \u001b[91m☒\u001b[0m 409 \n",
      "Q 22+519  T 541  \u001b[91m☒\u001b[0m 530 \n",
      "Q 232+9   T 241  \u001b[91m☒\u001b[0m 239 \n",
      "Q 444+73  T 517  \u001b[91m☒\u001b[0m 516 \n",
      "Q 22+62   T 84   \u001b[91m☒\u001b[0m 86  \n",
      "Q 864+704 T 1568 \u001b[91m☒\u001b[0m 1577\n",
      "Q 942+22  T 964  \u001b[92m☑\u001b[0m 964 \n",
      "Q 299+27  T 326  \u001b[91m☒\u001b[0m 321 \n",
      "Q 94+5    T 99   \u001b[91m☒\u001b[0m 90  \n",
      "Q 42+219  T 261  \u001b[91m☒\u001b[0m 250 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 24s 538us/step - loss: 0.8074 - accuracy: 0.7055 - val_loss: 0.7909 - val_accuracy: 0.7134\n",
      "Q 236+337 T 573  \u001b[91m☒\u001b[0m 580 \n",
      "Q 531+949 T 1480 \u001b[91m☒\u001b[0m 1482\n",
      "Q 182+468 T 650  \u001b[92m☑\u001b[0m 650 \n",
      "Q 87+876  T 963  \u001b[91m☒\u001b[0m 962 \n",
      "Q 576+89  T 665  \u001b[92m☑\u001b[0m 665 \n",
      "Q 629+45  T 674  \u001b[91m☒\u001b[0m 671 \n",
      "Q 517+514 T 1031 \u001b[91m☒\u001b[0m 1028\n",
      "Q 37+767  T 804  \u001b[91m☒\u001b[0m 809 \n",
      "Q 860+78  T 938  \u001b[91m☒\u001b[0m 942 \n",
      "Q 166+1   T 167  \u001b[91m☒\u001b[0m 162 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "25600/45000 [================>.............] - ETA: 10s - loss: 0.7749 - accuracy: 0.7192"
     ]
    }
   ],
   "source": [
    "\n",
    "# 实现一个用来执行加法的序列到序列学习模型\n",
    "'''\n",
    "输入: \"535+61\"\n",
    "\n",
    "输出: \"596\"\n",
    "\n",
    "使用重复的标记字符（空格）处理填充。\n",
    "\n",
    "输入可以选择性地反转，它被认为可以提高许多任务的性能，例如：\n",
    "[Learning to Execute](http://arxiv.org/abs/1410.4615)\n",
    "以及\n",
    "[Sequence to Sequence Learning with Neural Networks](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)。\n",
    "\n",
    "从理论上讲，它引入了源和目标之间的短期依赖关系。\n",
    "\n",
    "两个反转的数字 + 一个 LSTM 层（128个隐藏单元），在 55 个 epochs 后，5k 的训练样本取得了 99% 的训练/测试准确率。\n",
    "\n",
    "三个反转的数字 + 一个 LSTM 层（128个隐藏单元），在 100 个 epochs 后，50k 的训练样本取得了 99% 的训练/测试准确率。\n",
    "\n",
    "四个反转的数字 + 一个 LSTM 层（128个隐藏单元），在 20 个 epochs 后，400k 的训练样本取得了 99% 的训练/测试准确率。\n",
    "\n",
    "五个反转的数字 + 一个 LSTM 层（128个隐藏单元），在 30 个 epochs 后，550k 的训练样本取得了 99% 的训练/测试准确率。\n",
    "\n",
    "\n",
    "# '''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "\n",
    "\n",
    "class CharacterTable(object):\n",
    "    \"\"\"给定一组字符：\n",
    "    + 将它们编码为 one-hot 整数表示\n",
    "    + 将 one-hot 或整数表示解码为字符输出\n",
    "    + 将一个概率向量解码为字符输出\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"初始化字符表。\n",
    "\n",
    "        # 参数：\n",
    "            chars: 可以出现在输入中的字符。\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"给定字符串 C 的 one-hot 编码。\n",
    "\n",
    "        # 参数\n",
    "            C: 需要编码的字符串。\n",
    "            num_rows: 返回的 one-hot 编码的行数。\n",
    "                      这用来保证每个数据的行数相同。\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"将给定的向量或 2D array 解码为它们的字符输出。\n",
    "\n",
    "        # 参数\n",
    "            x: 一个向量或 2D 概率数组或 one-hot 表示，\n",
    "               或 字符索引的向量（如果 `calc_argmax=False`）。\n",
    "            calc_argmax: 是否根据最大概率来找到字符，默认为 `True`。\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n",
    "\n",
    "# 模型和数据的参数\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# 输入的最大长度是 'int+int' (例如, '345+678'). int 的最大长度为 DIGITS。\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# 所有的数字，加上符号，以及用于填充的空格。\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # 跳过任何已有的加法问题\n",
    "    # 同事跳过任何 x+Y == Y+x 的情况(即排序)。\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # 利用空格填充，是的长度始终为 MAXLEN。\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # 答案可能的最长长度为 DIGITS + 1。\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # 反转查询，例如，'12+345  ' 变成 '  543+21'. \n",
    "        # (注意用于填充的空格)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# 混洗 (x, y)，因为 x 的后半段几乎都是比较大的数字。\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# 显式地分离出 10% 的训练数据作为验证集。\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "# 可以尝试更改为 GRU, 或 SimpleRNN。\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# 利用 RNN 将输入序列「编码」为一个 HIDDEN_SIZE 长度的输出向量。\n",
    "# 注意：在输入序列具有可变长度的情况下,\n",
    "# 使用 input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# 作为解码器 RNN 的输入，为每个时间步重复地提供 RNN 的最后输出。\n",
    "# 重复 'DIGITS + 1' 次，因为它是最大输出长度。\n",
    "# 例如，当 DIGITS=3, 最大输出为 999+999=1998。\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# 解码器 RNN 可以是多个堆叠的层，或一个单独的层。\n",
    "for _ in range(LAYERS):\n",
    "    # 通过设置 return_sequences 为 True, 将不仅返回最后一个输出，而是返回目前的所有输出，形式为(num_samples, timesteps, output_dim)。\n",
    "    # 这是必须的，因为后面的 TimeDistributed 需要第一个维度是时间步。\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# 将全连接层应用于输入的每个时间片。\n",
    "# 对于输出序列的每一步，决定应选哪个字符。\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# 训练模型，并在每一代显示验证数据的预测。\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # 从随机验证集中选择 10 个样本，以便我们可以看到错误。\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
